# AI.
#### 28 August, 2024

If you are reading this article, you would know about the AI craze that has been happening over the past few years. It has died down from the absolute mania of 2023, with ChatGPT ripping up the scene. Google also come in with it's own AI models, and Bing started being good enough to use (somehow). 

That has all passed, though. And now i can give my take on it. Well, what is AI? AI, in its broadest sense, is computers being smart. That might sound weird, as we have smartphones and smartTVs and whatnot. The level of smart i am talking about is a computer able to exhibit its own form of humane-like intelligence. We have been using AI for quite a long time, even if it didn't get advertised. Most algorithms, like Youtube's, are Artificial Intelligence. The way that google presents it's results is also artificial intelligence. You could also say that LSPs are a sort of AI: it understands the  codebase and provides information on that codebase.  AI as we see it today is now based on the same fundamental concepts as the invisible AI. The difference is that there has been one type of AI that has proliferated: Gen AI. 

We'll get more into gen ai later. But first of all, we have to understand why AI is so important in today. AI, when it wasn't sold as a product , had a goal of doing simple tasks: doing math, recommend videos, sorting out stuff. It was a tool of automation. Automation is quite normal, and companies will automate if it is good for them. Now, the AI that we see today is more than that: It can generate text, code, images and other stuff. AI is now turned from a background tool to an actual product.

 And one of the most prolific examples of AI as a product is Generative AI. This is a type of AI trains of information and then gives information as output. There are different types of output, such as text and video. Gen AI creates "new" stuff, and doesn't tinker existing information.  It has been there is one form or another for a couple of years, with AI research start in 1956. But the first time it went mainstream was with ChatGPT. I remember seeing it breaking the all-time record to 100 Million users in just two months. Granted, internet penetration and social media had increased by that time. It was still amazing to see how popular gen AIs where in such a short time. 

Then came it's main competitor: Google's Gemini. I won't delve much into Gemini but when it came out, it didn't really come out with much fanfare. It always played second fiddle to ChatGPT and even if it was better, it was always underrated. There was also Bing AI, which was basically ChatGPT but with internet. This was an answer to Gemini's ability to be up-to-date thanks to Google Search indexing. There is now Anthropic with it's Claude which is pretty good. There is also Mistral.

In my opinion, AI is a good product. It is amazing for helping with short tasks and is a good way to avoid typing boilerplate 15 million times. AI is also good at giving outline to stuff and text-to-speech is a godsend. Gemini Live and ChatGPT calling is great for just thinking aloud and having a check in place to ensure what you are thinking makes sense. It is a good proofreader and can hep find errors in storytelling and potholes. Google Photo's AI editing features are great! Those are just some things that I find great with AI and i hope the the field is going into a direction where it is easier and more helpful for the everyday. 

AI also has some issues, it is slow sometimes, it has the object performance of a two-year-old. It is not good at understanding its surroundings. It is bad at logic, it cannot see obvious context and AIs like Gemini has narrow things to understand. It is bad at understanding 3D spaces and is unable to draw intricate objects. So AI is still clearly lacking with some stuff. It is built as a math machine, finding the most probable answer and cannot do a fundamental human thing: nuance.

I do like AI, though. It is a budding industry and has far to go. It is great to see how the space developments and how the we as a society have to deal with it. But, the main problem of AI is that it is over-hyped. When a new product inevitably gets developed, there is a flood of bad actors and subpar ideas. Most of the time, their goal isn't to hep the people they are serving, but to make profit and leave. There are also a lot of moral issues with Gen AI. How are we going to ensure that artists are preserved and don't get even more prosecuted than they already are? There is also a problem of hallucination, which what the Journalist industry calls misinformation. These can cause riots, revolts and even genocide. We also have to ensure how AI doesn't drastically affect how people live, which is also an issue. 

AI, like any new technology, has hype. I'm not a fan of hype, and most of the time, it doesn't actually do anything large. AI has also suffered from this. Case in point: NVIDIA. There has been so many new products that must to have AI and most of them are not viable. This can cause a dot-com bubble like environment which can lead to jobs being lost and a very good AI industry being set back decades. 

All i am saying is: AI is a good thing, but like with all things, they can go bad if they are overused. I just hope that the amount of AI startups decrease without an external shock causing it. And hopefully, we have AI implementations that are safe, useful and good for humanity.