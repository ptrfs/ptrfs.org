<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ptr's website</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap"
      rel="stylesheet"
    />
  </head>
  <body
    style="
      font-family: 'JetBrains Mono';
      background-color: #fcfcf8;
      padding: 10px;
      width: 45%;
      margin: auto;
    "
  >
    <header
      style="align-items: center; text-align: center; justify-content: center"
    >
      <a href="../index.html" style="text-decoration: none; color: black"
        >ptr's website</a
      >
      <hr />
    </header>

    <h1>AI.</h1>
    <h4>28 August, 2024</h4>
    <p>
      If you are reading this article, you would know about the AI craze that
      has been happening over the past few years. It has died down from the
      absolute mania of 2023, with ChatGPT ripping up the scene. Google also
      came in with its own AI models, and Bing started being good enough to use
      (somehow).
    </p>
    <p>
      That has all passed, though. And now I can give my take on it. Well, what
      is AI? AI, in its broadest sense, is computers being smart. That might
      sound weird, as we have smartphones and smart TVs and whatnot. The level
      of smart I am talking about is a computer able to exhibit its own form of
      human-like intelligence. We have been using AI for quite a long time, even
      if it didn't get advertised. Most algorithms, like YouTube's, are
      Artificial Intelligence. The way that Google presents its results is also
      artificial intelligence. You could also say that LSPs are a sort of AI: it
      understands the codebase and provides information on that codebase. AI as
      we see it today is now based on the same fundamental concepts as the
      invisible AI. The difference is that there has been one type of AI that
      has proliferated: Gen AI.
    </p>
    <p>
      We'll get more into Gen AI later. But first of all, we have to understand
      why AI is so important today. AI, when it wasn't sold as a product, had a
      goal of doing simple tasks: doing math, recommending videos, sorting out
      stuff. It was a tool of automation. Automation is quite normal, and
      companies will automate if it is good for them. Now, the AI that we see
      today is more than that: It can generate text, code, images, and other
      stuff. AI is now turned from a background tool to an actual product.
    </p>
    <p>
      And one of the most prolific examples of AI as a product is Generative AI.
      This is a type of AI that trains on information and then gives information
      as output. There are different types of output, such as text and video.
      Gen AI creates "new" stuff and doesn't tinker with existing information.
      It has been there in one form or another for a couple of years, with AI
      research starting in 1956. But the first time it went mainstream was with
      ChatGPT. I remember seeing it breaking the all-time record to 100 million
      users in just two months. Granted, internet penetration and social media
      had increased by that time. It was still amazing to see how popular Gen
      AIs were in such a short time.
    </p>
    <p>
      Then came its main competitor: Google's Gemini. I won't delve much into
      Gemini, but when it came out, it didn't really come out with much fanfare.
      It always played second fiddle to ChatGPT, and even if it was better, it
      was always underrated. There was also Bing AI, which was basically ChatGPT
      but with the internet. This was an answer to Gemini's ability to be
      up-to-date thanks to Google Search indexing. There is now Anthropic with
      its Claude, which is pretty good. There is also Mistral.
    </p>
    <p>
      In my opinion, AI is a good product. It is amazing for helping with short
      tasks and is a good way to avoid typing boilerplate 15 million times. AI
      is also good at giving outlines to stuff, and text-to-speech is a godsend.
      Gemini Live and ChatGPT calling are great for just thinking aloud and
      having a check in place to ensure what you are thinking makes sense. It is
      a good proofreader and can help find errors in storytelling and plot
      holes. Google Photo's AI editing features are great! Those are just some
      things that I find great with AI, and I hope the field is going in a
      direction where it is easier and more helpful for the everyday.
    </p>
    <p>
      AI also has some issues. It is slow sometimes, it has the object
      performance of a two-year-old. It is not good at understanding its
      surroundings. It is bad at logic, it cannot see obvious context, and AIs
      like Gemini have narrow things to understand. It is bad at understanding
      3D spaces and is unable to draw intricate objects. So AI is still clearly
      lacking in some areas. It is built as a math machine, finding the most
      probable answer and cannot do a fundamental human thing: nuance.
    </p>
    <p>
      I do like AI, though. It is a budding industry and has far to go. It is
      great to see how the space develops and how we as a society have to deal
      with it. But, the main problem of AI is that it is over-hyped. When a new
      product inevitably gets developed, there is a flood of bad actors and
      subpar ideas. Most of the time, their goal isn't to help the people they
      are serving, but to make a profit and leave. There are also a lot of moral
      issues with Gen AI. How are we going to ensure that artists are preserved
      and don't get even more persecuted than they already are? There is also a
      problem of hallucination, which the journalism industry calls
      misinformation. These can cause riots, revolts, and even genocide. We also
      have to ensure that AI doesn't drastically affect how people live, which
      is also an issue.
    </p>
    <p>
      AI, like any new technology, has hype. I'm not a fan of hype, and most of
      the time, it doesn't actually do anything large. AI has also suffered from
      this. Case in point: NVIDIA. There have been so many new products that
      must have AI, and most of them are not viable. This can cause a dot-com
      bubble-like environment which can lead to jobs being lost and a very good
      AI industry being set back decades.
    </p>
    <p>
      All I am saying is: AI is a good thing, but like with all things, it can
      go bad if it is overused. I just hope that the number of AI startups
      decreases without an external shock causing it. And hopefully, we have AI
      implementations that are safe, useful, and good for humanity.
    </p>
  </body>
</html>
